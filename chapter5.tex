\chapter{結論}
\newpage

\section{総括}
本研究では，上肢機能障害者支援を目指し，強化学習・深層学習をロボット制御に適用した自律型ロボットハンドの試作を行った．携帯できるくらい小型軽量化し，Cloudは使用せずEdgeで処理を行えるようにした．今回開発したロボットハンドは指定した物体を識別し，接近し，把持し，使用者のもとへ運搬するタスクを達成できた．

\subsection*{試作1号機}
1号機ではスマートフォンを搭載し，スマートフォンのカメラとCPUのみによる強化学習で，特定の色の物体への接近と把持に成功した．重量も電動義手よりも軽く，使用者の負担にはならないと言える．リハビリテーション科に通う義手使用患者へヒアリングを実施した際も1号機は好評で，障害者支援への実用化が期待できる．

一方で，計算リソースの都合上対象物の識別はできず，事前に指定した物体の色のみしか判断できない点が課題である．

\subsection*{試作2号機}
2号機では1号機と比べ，画像認識技術と深層学習により複数の物体がある中でも対象物を識別できる点が改善された．また，ハードウェアの機械的自由度を増やし，物体を持ち上げて運搬することが可能となった．識別を確認した物体は4種類で，ボトルの把持成功率は9割であった．

一方で，計算リソースの都合上GPUを搭載したデスクトップPCと有線で接続されているため，携帯性が低下した．また，ロボットハンドの重量が軽いために，ロボット本体重量以上の重い物体を持ち上げることができないといった課題が残る．しかし本体重量を上げることは簡単であるため，大きな課題では無いと言える．そして次の節で述べるように，Edgeデバイスを用いることで携帯性は改善できる．


\section{今後の展望}\label{sec:今後の展望}
ロボットハンドの本体のデザイン，アクチュエータや計算リソースのハードウェア，アクチュエータの制御や画像処理を行うソフトウェアの3つの観点から，改善指針として以下にまとめる．

\subsection*{デザインの改善}
地面から直立している物体のみで，平たい物体や細長く自立しない物体などは把持不可能であった．そのため，腕の関節と手首の関節を増やすことで，地面に対して垂直にアプローチできるように改善すると把持できる物体の幅が広がる．また，今回グリッパは大した考慮をしていなかったため，様々な物体を把持可能であるJammingグリッパ\cite{jamminggripper}など，グリッパ形状を検討する必要がある．

\subsection*{ハードウェア（計算リソース）の改善}
2号機では識別能力を向上させるために，外部の計算リソースを使用していたためGPU搭載PCと有線で接続されていたことが大きな課題であった．そこで次世代機ではEdgeデバイスであるJetsonNanoを使用することで，localでもGPUを使用した推論が可能となる．さらにJetsonNanoはanalogWriteができるため，Arduinoを必要とせずアクチュエータの制御が可能となり，よりシンプルな設計にできると考えられる．

\subsection*{ソフトウェアの改善}
接近タスクは比例制御で十分有効であることがわかったが，把持タスクはルールベースでは物体の形状に対称性が無いものは把持成功率が低かった．把持タスクにはVisionベースの教師あり学習を行い最適な把持点を掴むことで改善できる．さらに識別タスクに用いたMask R-CNNと合わせてモデルを構築できれば，End-to-Endに学習ができ精度改善や推論速度向上を期待できる．
