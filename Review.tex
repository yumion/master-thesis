\chapter{深層学習による病理画像の診断支援}
\label{chap_review}

病理画像をデジタルで保存することが始まったのは数十年前になる．これによって遠隔地でも診断することができるようになったり，情報を共有することができるようになり，複数の医師で診断しミスを防止するセカンド・オピニオンが容易になった．計算機科学の分野の側面ではデータを収集することができるようになり，研究が盛んに行われることになった．その後は，様々な病理データでより改良されたアルゴリズムの提案が行われている．

細胞組織の形態を観察するための病理染色ではヘマトキシリン・エオジン染色(HE染色)が一般的に用いられる．細胞核を青紫色に染色し，細胞質をピンク色に染色する．正常から異常に変化していくと，細胞核が過度に増殖したり，細胞質の形が崩れたりすることで，その特徴を機械学習によって精度よく検出するための研究が行われている．

これまでは，核の形やテキスチャーからパターンマッチングなどの画像処理によって腫瘍を検出する研究されてきたが，近年になって画像処理に大きなブレークスルーが起きたことをきっかけに，新しい手法で解析するようになってきた．そのブレークスルーがディープラーニングである．



\section{ニューラルネットワーク}
人間の脳にはニューロンと呼ばれる神経細胞が1000億個以上あり，それぞれが複数のニューロンと電気信号で情報を伝達している．また脳には電気信号を受け渡すシナプスという場所がある．ニューロンとシナプスで行われる演算を模倣したアルゴリズムを作ることができれば人間のような思考や認識をコンピュータを使って再現できると考えた．そのアルゴリズムがニューラルネットワークである．

\subsection{多層パーセプトロン}
ニューラルネットワークは入力層，出力層，隠れ層から構成され，層と層の間にはニューロン同士のつながりの強さを示す重みがある．非線形問題を扱うために 1986 年 Rumelhart によって考案されたのが，パーセプトロンを複数つなぎ合わせ入力と出力以外に隠れた層を持つ多層パーセプトロン (Multi-layer perceptron: MLP) である．

ニューラルネットワークで多層パーセプトロンの層を全結合(fully connected: FC) 層とも呼ぶ．Figure 3.1 における丸や矢印はそれぞれノード (またはニューロン) と重み (または結合) と呼び，ともに数値である．例えば画像を分類しようと思えば，各ピクセルの画素数を各ノードに入力する (28×28pix のグレースケール画像であれば 784 個のノードが必要)．データが入力層に入ってくると，その値に重みをかけ，活性化関数と呼ばれる関数を通し結果を出力する．これを繰り返し出力層に書き出す．各層の重みの値によって出力結果は異なってくる．出力層のノードは区別したいクラス数分用意し，各ノードの出力値が各クラスに属している確率を表す．学習については誤差逆伝播法を利用する．ニューラルネットワークの出力値と正解データとの比較をした時に，どれだけ正解から離れているかを評価する損失関数 (Loss) を使って，損失関数が小さくなるようにノード間の重みを勾配降下法によって更新する．

\subsection{畳み込みニューラルネットワーク}
畳み込みニューラルネットワーク (ConvolutionalNeural Network: CNN) は，1998 年には既に LeNetと呼ばれるネットワークで実装されていた [3]．従来の画像認識では，画像から特徴を抽出し，それをニューラルネットワークにかけるいわゆる特徴量設計が必要で，ここをいかにうまく設計するかがポイントであったが，CNN は特徴量設計から識別までを end-to-end で行うことがきることが最大の強みである．人間が物体を認識することをコンピュータにも計算させるには，画像の特徴的な部分を切り分けて数値化させる必要がある．例えば，カラー画像の場合，RGB の 3 色 (3 チャンネル)を組み合わせた画像で認識をしている．このようなフィルターの畳み込み計算を行うと，フィルターごとに異なった画像の特徴を抽出して数値化する．これが畳み込み (convolution) である．その後，画像のサイズを小さくしてコンピュータが計算コストを減らし，微小な変化に対してロバストになる仕組みしてプーリングという方法を用いる．学習には MLPと同様に誤差逆伝播法を用いる．


\subsection{再帰的ニューラルネットワーク}
再帰的ニューラルネットワーク(Recurrent Neural Network: RNN)
Long-short term memory(LSTM)


\begin{figure}[h]
\centering
\includegraphics[width=0.7\linewidth]{fig/lstm.png}
\caption{}
\label{fig:LSTM}
\end{figure}

\begin{align}\label{eq:LSTM}
  i_t & = \sigma(W_{xi} x_t + W_{hi} h_{t-1} + W_{ci} c_{t-1} + b_i) \\
  f_t & = \sigma(W_{xf} x_t + W_{hf} h_{t-1} + W_{cf} c_{t-1} + b_f ) \\
  c_t & = f_t c_{t-1} + i_t tanh(W_{xc} x_t + W_{hc} h_{t-1} + b_c) \\
  o_t & = \sigma(W_{xo} x_t + W_{ho} h_{t-1} + W_{co} c_t + b_o) \\
  h_t & = o_t tanh(c_t) 
\end{align}

ここで$\sigma$はシグモイド関数であり，次の式で定義される．
\begin{equation}\label{eq:sigmoid}
  \sigma (x) = \dfrac{1}{1 + e^{-x}}
\end{equation}


\section{画像認識におけるディープラーニング}
Deep Learning とは Deep Neural Network(DNN)を指すことが多い．この"Deep"とは，ニューラルネットワークの層が深いことに由来している．
Figure 3.3 に画像認識タスクの精度の近年の推移を示す．これは ImageNet Large Scale Visual RecognitionChallenge (ILSVRC) と呼ばれる世界的な画像認識のコンペティションである (2010 年から始まった)．カテゴリ数は 1000 クラスで，画像枚数は120 万枚の訓練データと 15 万枚のテストデータが用意されている．2011 年と 2012 年は約 10\%もの大差で AlexNet[4] が優勝している．これがディープラーニングの始まりである．AlexNet は 5 つの畳み込み層と 3 つの全結合層を持っている．2014 年には VGGNet[5] や GoogLeNet[6] が 9 割の精度を超えた．VGGNet は AlexNet(8 層) よりさらに深い構造(19 層) であり，GoogLeNet は 22 層もある．そして2015 年には ResNet[7] が人間の精度をも超える認識精度を達成した．ResNet は GoogLeNet よりもさらに深く 152 層もある．一般に，層を深くすることは簡単ではなく，勾配消失や過学習といった問題が起こる．CNNを複数回かけて検出を行う場合、CNNの浅い側では空間分解能はあるが抽象的な情報が少ない。深い側では意味論的な情報は取得できる（ポーズ、変形など） が空間分解能が小さいため幾何学的な情報が失われる。アーキテクチャの進化の方向は①層が深くなること ②FC層の使用を避けること又はInceptionモジュールの使用によってパラメータ数を削減すること ③ ResNetなどのショートカット接続によって学習効率をあげること事前学習・転移学習を行うことでモデルの精度を上げる取り組みがある．当然ながらこの場合事前学習のデータセットと適用データとの間に類似性があると良い。

画像処理におけるディープラーニングでは大きく3つのタスクがあり，それぞれ，クラス分類，物体検出，セグメンテーションである．以下に詳細を述べる．

\subsection*{クラス分類}
カテゴリ分けをすること

\subsection*{物体検出}
物体検出とはBounding Boxで物体の位置とその物体の種類を特定する方法である．歴史的には幾何的情報，手動特徴量，そしてそのカスケードを利用していた．その後，HOGやSIFTなど局所特徴量を抽出する方法を設計するようになったが、これは深い専門知識を必要とした．また広い範囲でオブジェクトを正確に検出する方法は、メモリ容量と処理時間に課題がある．現在はDeep Neural Networkになりデータのみから抽象的な特徴量を複数得ることができる。一般物体認識の場合は数千のカテゴリを学習してTop Error Rateが2\%以下と人間よりも認識精度が高いが，物体検出においては，今はカテゴリがせいぜい数百程度くらいまででも認識精度が人間よりも低くなってしまう．また物体検出は精度を上げるために処理に時間がかかるアルゴリズムであることが多いため，リアルタイムに物体検出を行う時は，速度と精度でトレードオフが生じてしまう．

\begin{figure}[h]
\centering
\includegraphics[width=0.7\linewidth]{fig/yolo_ssd.png}
\caption{}
\label{fig:YOLO}
\end{figure}

\subsection*{セグメンテーション}
セマンティックセグメンテーションとは，画像を画素レベルで認識することである．画像内の各画素をオブジェクトクラスに割り当てる手法である．セマンティックセグメンテーションの手法についてディープラーニング以前では，Texton Forestsや，Random Forestsに基づいた分類を行っていたが，物体検出と同様にCNNが登場してからは，高精度なセグメンテーションが実現するようになった．CNNを使ったセグメンテーションの手法で一般的に使われるようになったものがUnetである(\fig {Unet})．このUnetは文字通りUの形をしたネットワークであることが特徴で，２つのアーキテクチャーからできている．一つ目がエンコーダーのアーキテクチャーでCNNとプーリングで特徴を抽出しながら次元を削減していき，２つ目のデコーダーのアーキテクチャーで画像をセグメンテーションの結果になるように復元する．ここで問題になることが，プーリングをすることで位置情報を消してしまっているので，この位置情報を利用して画像を復元するためには，エンコーダーとデコーダーで画像サイズが同じところ同士をショートカットで接続することがUnet構造の優れている点である．

\begin{figure}[h]
\centering
\includegraphics[width=0.7\linewidth]{fig/unet.png}
\caption{}
\label{fig:Unet}
\end{figure}

\section{深層学習による3次元画像解析}
ディープラーニングを医療画像に応用するコンペティションが世界で行われているが、その半数が3D医療画像の解析になっているほど需要が高まっている。その理由は、現在解決しなくてはならない課題があるからである。まずは2次元画像と違って、処理するべきデータが大きいということである。そのため学習するパラメータをなるべく少なくする工夫がされている。また3次元画像には、動画または、ボリューム画像があるが、2次元画像とその深さ方向(動画であれば、時間方向)には異方性があることから、機械学習の方法に工夫が必要になる。今まで考案されている手法として、2DCNNを拡張した3DCNN、またCNNと時系列解析でよく用いられるLSTMを組み合わせた手法と、LSTM内部にCNNを組み込んだ手法、それらをすべて組み合わせた手法が考案されいる。LSTMの研究も盛んに行われているため、その改良モデルが数多く存在する。特に、LSTMの学習効率を上げたGRU(Gated Linear Unit)や、順方向だけでなく逆方向の時系列も計算に入れるBiLSTMが時系列解析の精度向上になっている報告がある。


\subsection{3D CNNとStacked Convolution}
2次元画像が深さ方向に連続している3次元画像の特徴を抽出するために、2次元のCNNを拡張して、3次元のカーネルを使って畳み込みを行う、3DCNNを利用した手法がある。

\begin{figure}[h]
\centering
\includegraphics[width=0.7\linewidth]{fig/3d_cnn.png}
\caption{}
\label{fig:}
\end{figure}


\begin{figure}[h]
\centering
\includegraphics[width=0.7\linewidth]{fig/stacked_conv.png}
\caption{}
\label{fig:}
\end{figure}

\subsection{LSTMとその派生系}
LSTM+2DCNNの話


\section{ディープラーニングを用いた病理画像診断}
学習した結果を評価するときに医療画像の場合は、PrecisionとRecallを識別性能の評価指数として使う。

\begin{align}
  \mathrm{Precision} & = \dfrac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FP}}\\
  \mathrm{Recall} & = \dfrac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}}
\end{align}

ここで使ったTP(True Positive)は真の結果が正である時に予測も正であるという意味であるTN(True Negative)は真の結果が正で予測が負である場合である。同様にFP(False Positive)真の結果が負で予測も負、FN(False Negative)真の結果が負で予測は正である．

2016年に行われたCAMELYON16という乳がんの転移を調べるシステムのコンペティションでは、7人の医師の成績を上回っていることが報告されてている。

また皮膚癌の種類が757種類を細かい違いまで識別するように学習する。学習方法はInception v3というネットワークを利用している。これは22層の畳み込みニューラルネットワークである。またこのネットワークは皮膚癌の識別タスクを学習する前に、ImageNetというILSVCでも使っている一般物体画像を使って事前にネットワークの重みの初期値を決めることによって、精度が向上させる。これを転移学習(Transfer Learning)と呼ばれている。


\section{教師なし学習}
機械学習の手法には、上記で説明したように、ラベルの貼られているデータセットを用いて学習することを教師あり学習と呼び、その反対で、データセットはあっても、そのデータセットの特性を示したラベルが与えられていない場合のデータセットを用いて学習することを教師なし学習と呼ぶ。

ここで教師なし学習で画像の特徴を抽出する方法としてオートエンコーダがある。画像の場合におけるオートエンコーダの手法とは、ある画像から情報を圧縮する「エンコーダ」と言われる部分と、その圧縮した情報から画像を復元する「デコーダ」の二つからなる。入力とデコーダから復元された画像が同じ画像になるようにニューラルネットワークで学習させる。この学習の結果、潜在変数は似てる画像どうしで近い値になるように変化し、この分布を見れば画像の分類を教師ラベルがなくても、学習を行うことができる。本研究では、このオートエンコーダの派生である。Variational Autoencoder(VAE)を利用した。これはオートエンコーダの「エンコーダ」と「デコーダ」は同じネットワーク構造であるが、データセットの潜在変数の分布が、正規分布になるような制約を加えて学習を行う手法である。こうすることでAutoencoderの潜在変数では分布の距離に意味なかったが、Variational Autoencoderでは正規分布に埋め込まれるため、画像の類似度を分布が表現することができるところが特徴である。Variational Autoencoderをまずは、2Dの画像に対して分布が正常と腫瘍の画像で変化するのかを確認した。さらに3次元画像でも解析することで3DCNNを用いて画像をエンコーダのネットワークを作り、潜在変数の空間を作ることで3次元画像特有の情報を抽出することができ、2次元画像だけでは判断できない、血管構造の乱れなどが認識できるようになると考えられる。

\section{半教師あり学習}
弱教師あり学習とも呼ばれる．

